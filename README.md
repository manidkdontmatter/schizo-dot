There are two modes for the backend. Either using a local model that is transformers.js bart-large-nli zero shot classification, or send the posts off to Grok and let Grok decide. Both work, but Grok is faster, cheaper, and seems to provide more nuanced accurate results.